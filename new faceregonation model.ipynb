{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfrom keras.models import Sequential\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.layers import BatchNormalization, Dense, Input, GlobalMaxPooling2D, MaxPooling2D,Flatten,Concatenate\nfrom keras.models import Model\nimport keras.backend as K\nimport shutil\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"class batch_generator:\n    def __init__(self,batch_size=256,\n                 target_size=(128,128),\n                 horizontal_flip=False,\n                 rescale=1,\n                 rotate=False,\n                 other_transform = False,\n                 path = \"\",\n                 \n                ):\n        self.batch_size=batch_size\n        self.target_size = target_size\n        self.horizontal_flip = horizontal_flip\n        self.rescale = rescale\n        self.rotate = rotate\n#         self.color_argumentation = color_argumentation\n        self.other_transform = other_transform\n        self.path = path\n        self.x_shift = 0.5 * self.target_size[0]\n        coeffs = self.find_coeffs(\n            [(0, 0), (256, 0), (256, 256), (0, 256)],\n            [(0, 0), (256, 0), (self.target_size[0], self.target_size[1]), (self.x_shift, self.target_size[1])])\n        \n    \n    def __iter__(self):\n        return self\n    \n    def read_image(self):\n        dir_list = os.listdir(self.path)\n        original = random.choice(dir_list)\n        dir_list.remove(original)\n        fake = random.choice(dir_list)\n        img_list = os.listdir(os.path.join(self.path,original))\n        anchor = random.choice(img_list)\n        img_list.remove(anchor)\n        positive = random.choice(img_list)\n        img_list = os.listdir(os.path.join(self.path,fake))\n        negative = random.choice(img_list)\n        \n        anchor_image = Image.open(os.path.join(self.path,original,anchor))\n        negative_image = Image.open(os.path.join(self.path,fake,negative))\n        positive_image = Image.open(os.path.join(self.path,original,positive))\n        \n        anchor_image = anchor_image.resize(self.target_size, Image.NEAREST) \n        positive_image = positive_image.resize(self.target_size, Image.NEAREST) \n        negative_image = negative_image.resize(self.target_size, Image.NEAREST)\n        \n        anchor_image = np.array(self.transform(anchor_image))\n        positive_image = np.array(self.transform(positive_image))\n        negative_image = np.array(self.transform(negative_image))\n        \n        \n        return (anchor_image,positive_image,negative_image)\n        \n        \n        \n        \n    def transform(self,img):\n        \n        if self.horizontal_flip and random.choice([True,False]) :\n            img = img.transform(self.target_size,Image.FLIP_LEFT_RIGHT)\n            \n        if self.rotate :\n            deg = random.randrange(0,359)\n            img = img.rotate(deg)\n            \n        if self.other_transform :\n            r = random.choice([True,False])\n            if r:\n                img = img.transform(self.target_size, Image.PERSPECTIVE, coeffs,Image.BICUBIC)\n            else:\n                img = img.transform(self.target_size, Image.AFFINE,(1, -0.5, -self.x_shift if -0.5 > 0 else 0, 0, 1, 0), Image.BICUBIC)\n        \n        return img\n    \n    def find_coeffs(self,pa, pb):\n        matrix = []\n        for p1, p2 in zip(pa, pb):\n            matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n            matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n\n        A = np.matrix(matrix, dtype=np.float)\n        B = np.array(pb).reshape(8)\n\n        res = np.dot(np.linalg.inv(A.T * A) * A.T, B)\n        return np.array(res).reshape(8)\n\n    \n    def __next__(self):\n        anchor = np.zeros((self.batch_size,)+self.target_size+(3,))\n        positive = np.zeros((self.batch_size,)+self.target_size+(3,))\n        negative = np.zeros((self.batch_size,)+self.target_size+(3,))\n        \n        for i in range(self.batch_size):\n            a,p,n = self.read_image()\n            anchor[i] = a\n            positive[i] = p\n            negative[i] = n\n            \n        return ([anchor*self.rescale,positive*self.rescale,negative*self.rescale],np.zeros((self.batch_size,3*128)))\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(128,128,3))\n\nx = vgg16.output\noutput = GlobalMaxPooling2D()(vgg16.output)\npre_trained = Model(vgg16.input, output)\nfor layer in vgg16.layers:\n    layer.trainable = False\n# for layer in vgg16.layers[8:]:\n#     layer.trainable = True\n    \n    \ndef base_model(input_shape):\n    input = Input((input_shape,), name=\"input\")\n    \n    x = Dense(1024,activation=\"relu\")(input)\n    \n    x = Dense(128)(x)\n    \n    return Model(input,x)\n\nconv_feat_size = K.int_shape(pre_trained.output)[-1]\nbase = base_model(conv_feat_size)\n\ndef Final_model(pre_trained):\n    inp_shape = K.int_shape(pre_trained.input)[1:]\n    \n    input1 = Input(inp_shape, name=\"anchor\")\n    input2 = Input(inp_shape, name=\"postive\")\n    input3 = Input(inp_shape, name=\"negative\")\n    \n    \n    output1 = base(pre_trained(input1))\n    output2 = base(pre_trained(input2))\n    output3 = base(pre_trained(input3))\n    \n    concat = Concatenate(axis=-1)([output1,output2,output3])\n    \n    return Model([input1,input2,input3],concat)\n\nFinal_model = Final_model(pre_trained)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def triplet_loss(y_true, y_pred, alpha = 0.2):\n    embedding_size = K.int_shape(y_pred)[-1] // 3\n    ind = int(embedding_size * 2)\n    a_pred = y_pred[:, :embedding_size]\n    p_pred = y_pred[:, embedding_size:ind]\n    n_pred = y_pred[:, ind:]\n   \n    positive_distance = K.sqrt(K.sum(K.square(a_pred - p_pred), axis=-1))\n    negative_distance = K.sqrt(K.sum(K.square(a_pred - n_pred), axis=-1))\n    \n    loss = K.maximum(0.0, positive_distance - negative_distance + alpha)\n    return loss\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_model.compile(loss=triplet_loss,optimizer=\"adam\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/facedatasets/facedata/faceData/\"\ntest_gen = iter(batch_generator(path=path, \n                                target_size=(128,128),\n                                horizontal_flip=False,\n                                rotate=True,\n                                other_transform = False,\n                                rescale=1./256,\n                                batch_size=16))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_model.fit_generator(test_gen,epochs=10,validation_data=test_gen, validation_steps= 100, steps_per_epoch=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y = next(test_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_predict = base.predict(pre_trained.predict(x[0,:,:,:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ = pre_trained.predict(x[0,:,:,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.predict(y_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://thenypost.files.wordpress.com/2019/05/selena-gomez-cannes.jpg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://static-ssl.businessinsider.com/image/57fe6c004046ddf8008b5668-2400/ap_616611858368.jpg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://www.biography.com/.image/t_share/MTI2NDQwNDA2NTg5MTUwNDgy/ariana-grande-shutterstock_213445195-600x487jpg.jpg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img1 = Image.open('./ap_616611858368.jpg')\nimg1 = img1.resize((128,128),Image.NEAREST)\nimg1 = np.array(img1)\n\nimg2 = Image.open('./selena-gomez-cannes.jpg')\nimg2 = img2.resize((128,128),Image.NEAREST)\nimg2 = np.array(img2)\n\nimg3 = Image.open('./ariana-grande-shutterstock_213445195-600x487jpg.jpg')\nimg3 = img3.resize((128,128),Image.NEAREST)\nimg3 = np.array(img3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_gen = iter(batch_generator(path='../input/onshottesting/testing/testing/', \n                                target_size=(128,128),\n                                horizontal_flip=False,\n                                rotate=True,\n                                other_transform = False,\n                                rescale=1./255,\n                                batch_size=16))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_,y_ = next(val_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ = base.predict(pre_trained.predict(x_[0]))\ny__ = base.predict(pre_trained.predict(x_[1]))\ny___ = base.predict(pre_trained.predict(x_[2]))\ny____ = base.predict(pre_trained.predict(x_[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = Final_model.predict(x_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y[0].shape[0]/4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(1-np.sum(Y[i][128:2*128]*Y[i][3*128:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}